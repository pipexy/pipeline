# advanced_pipelines.yaml
pipelines:
  order-processing:
    description: "Kompleksowy pipeline przetwarzania zamówień"
    steps:
      - adapter: http_client
        methods:
          - name: url
            value: "http://127.0.0.1:5000/api/orders"
          - name: method
            value: "GET"

      - adapter: python
        methods:
          - name: code
            value: |
              # Znajdź zamówienie po ID
              order_id = params.get('order_id')
              order = next((o for o in input_data.get('orders', []) if o['id'] == order_id), None)
              
              if not order:
                  result = {'error': f'Order {order_id} not found', 'status': 'not_found'}
              else:
                  result = order

      - adapter: http_client
        methods:
          - name: url
            value: "http://127.0.0.1:5000/api/process-payment"
          - name: method
            value: "POST"
          - name: headers
            value:
              Content-Type: "application/json"

      - adapter: python
        methods:
          - name: code
            value: |
              # Sprawdź status płatności
              if not input_data.get('success', False):
                  result = {
                      'error': 'Payment failed',
                      'payment_details': input_data,
                      'status': 'payment_failed'
                  }
              else:
                  result = {
                      'order': params.get('order'),
                      'payment': input_data,
                      'status': 'payment_successful'
                  }

      - adapter: database
        methods:
          - name: type
            value: "sqlite"
          - name: connection
            value: "orders.db"
          - name: query
            value: |
              INSERT INTO orders (id, user_id, total, payment_id, status)
              VALUES (:id, :user_id, :total, :payment_id, :status)

      - adapter: file
        methods:
          - name: path
            value: "./reports/order_{order_id}_{timestamp}.json"
          - name: operation
            value: "write"

  log-analysis:
    description: "Analiza logów dostępu do API"
    steps:
      - adapter: file
        methods:
          - name: path
            value: "./logs/api_access.log"
          - name: operation
            value: "read"

      - adapter: python
        methods:
          - name: code
            value: |
              # Parsowanie logów dostępu
              import json
              
              logs = [json.loads(line) for line in input_data.splitlines() if line]
              
              # Analiza statystyk
              endpoints = {}
              status_codes = {}
              
              for log in logs:
                  path = log['path']
                  status = log['status_code']
                  
                  if path not in endpoints:
                      endpoints[path] = {'count': 0, 'total_time': 0}
                      
                  endpoints[path]['count'] += 1
                  endpoints[path]['total_time'] += log['duration_ms']
                  
                  status_key = str(status)
                  status_codes[status_key] = status_codes.get(status_key, 0) + 1
              
              # Oblicz średnie czasy odpowiedzi
              for path, data in endpoints.items():
                  data['avg_time'] = data['total_time'] / data['count']
              
              result = {
                  'total_requests': len(logs),
                  'unique_endpoints': len(endpoints),
                  'endpoints': endpoints,
                  'status_codes': status_codes,
                  'timestamp': logs[-1]['timestamp'] if logs else None
              }

      - adapter: file
        methods:
          - name: path
            value: "./reports/api_stats_{today}.json"
          - name: operation
            value: "write"

  data-backup:
    description: "Wykonanie kopii zapasowej bazy danych"
    steps:
      - adapter: bash
        methods:
          - name: command
            value: "sqlite3 orders.db .dump > ./backups/orders_{today}.sql"

      - adapter: bash
        methods:
          - name: command
            value: "tar -czf ./backups/logs_{today}.tar.gz ./logs/"

      - adapter: python
        methods:
          - name: code
            value: |
              # Generowanie raportu z backupu
              import os
              import datetime
              
              today = datetime.datetime.now().strftime('%Y-%m-%d')
              db_backup = f'./backups/orders_{today}.sql'
              logs_backup = f'./backups/logs_{today}.tar.gz'
              
              db_size = os.path.getsize(db_backup) if os.path.exists(db_backup) else 0
              logs_size = os.path.getsize(logs_backup) if os.path.exists(logs_backup) else 0
              
              result = {
                  'backup_date': today,
                  'database': {
                      'path': db_backup,
                      'size_bytes': db_size,
                      'size_mb': round(db_size / (1024 * 1024), 2)
                  },
                  'logs': {
                      'path': logs_backup,
                      'size_bytes': logs_size,
                      'size_mb': round(logs_size / (1024 * 1024), 2)
                  },
                  'total_size_mb': round((db_size + logs_size) / (1024 * 1024), 2),
                  'status': 'completed'
              }

      - adapter: file
        methods:
          - name: path
            value: "./reports/backup_report_{today}.json"
          - name: operation
            value: "write"